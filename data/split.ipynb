{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(data, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as writer:\n",
    "        writer.write(\"\\n\".join(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervisely_face split: \n",
      "train: 1833\n",
      "valid: 305\n",
      "test: 917\n"
     ]
    }
   ],
   "source": [
    "# supervisely_face\n",
    "root = \"/workspace/liangjuhao/teaching/PortraitNet/assets/Supervisely_face\"\n",
    "group = \"SuperviselyPerson_ds*\"\n",
    "supervisely_ids = glob.glob(os.path.join(root, group, 'img', '*'))\n",
    "supervisely_ids = [p[len(root)+1:] for p in supervisely_ids]\n",
    "np.random.shuffle(supervisely_ids)\n",
    "data_length = len(supervisely_ids)\n",
    "train_size, valid_size = int(0.6*data_length), int(0.1*data_length)\n",
    "test_size = data_length - train_size - valid_size\n",
    "save(supervisely_ids[:train_size], os.path.join(\"splits\", \"supervisely_train.txt\"))\n",
    "save(supervisely_ids[train_size: train_size+valid_size], os.path.join(\"splits\", \"supervisely_valid.txt\"))\n",
    "save(supervisely_ids[train_size+valid_size: ], os.path.join(\"splits\", \"supervisely_test.txt\"))\n",
    "print(f\"Supervisely_face split: \\ntrain: {train_size}\\nvalid: {valid_size}\\ntest: {test_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EG1800 split: \n",
      "train: 1041\n",
      "valid: 173\n",
      "test: 522\n"
     ]
    }
   ],
   "source": [
    "# eg1800\n",
    "root = \"/workspace/liangjuhao/teaching/PortraitNet/assets/EG1800\"\n",
    "eg1800_ids = glob.glob(os.path.join(root, 'Images', '*'))\n",
    "eg1800_ids = [p[len(root)+1:] for p in eg1800_ids]\n",
    "np.random.shuffle(eg1800_ids)\n",
    "data_length = len(eg1800_ids)\n",
    "train_size, valid_size = int(0.6*data_length), int(0.1*data_length)\n",
    "test_size = data_length - train_size - valid_size\n",
    "save(eg1800_ids[:train_size], os.path.join(\"splits\", \"eg1800_train.txt\"))\n",
    "save(eg1800_ids[train_size: train_size+valid_size], os.path.join(\"splits\", \"eg1800_valid.txt\"))\n",
    "save(eg1800_ids[train_size+valid_size: ], os.path.join(\"splits\", \"eg1800_test.txt\"))\n",
    "print(f\"EG1800 split: \\ntrain: {train_size}\\nvalid: {valid_size}\\ntest: {test_size}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
